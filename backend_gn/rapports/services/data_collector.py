"""
Service de collecte de donn√©es pour les rapports
R√©cup√®re les donn√©es depuis la base PostgreSQL
"""

from datetime import datetime, timedelta
from django.db.models import Count, Q, Avg, Sum, F
from django.db.models.functions import TruncMonth, TruncDay
from django.utils import timezone
from typing import Dict, List, Any
from criminel.models import CriminalFicheCriminelle


class DataCollectorService:
    """Service de collecte de donn√©es pour les rapports"""
    
    def __init__(self, type_rapport: str, date_debut, date_fin, filtres: Dict = None):
        """
        Initialise le collecteur de donn√©es
        
        Args:
            type_rapport: Type de rapport √† g√©n√©rer
            date_debut: Date de d√©but de la p√©riode
            date_fin: Date de fin de la p√©riode
            filtres: Filtres suppl√©mentaires (statut, r√©gion, etc.)
        """
        self.type_rapport = type_rapport
        self.date_debut = date_debut
        self.date_fin = date_fin
        self.filtres = filtres or {}
    
    def collect_data(self) -> Dict[str, Any]:
        """
        Collecte les donn√©es selon le type de rapport
        
        Returns:
            dict: Donn√©es format√©es pour le rapport
        """
        collectors = {
            'resume_mensuel': self._collect_resume_mensuel,
            'statistiques_infractions': self._collect_statistiques_infractions,
            'activite_agents': self._collect_activite_agents,
            'fiches_ouvertes': self._collect_fiches_ouvertes,
            'analyse_geographique': self._collect_analyse_geographique,
            'taux_resolution': self._collect_taux_resolution,
            'biometrie': self._collect_biometrie,
            'personnalise': self._collect_personnalise,
        }
        
        collector = collectors.get(self.type_rapport, self._collect_personnalise)
        return collector()
    
    def _get_base_queryset(self):
        """
        Retourne le queryset de base filtr√© par dates et filtres
        Utilise les vraies donn√©es du mod√®le CriminalFicheCriminelle
        """
        import logging
        logger = logging.getLogger(__name__)
        
        from criminel.models import CriminalFicheCriminelle
        from django.utils import timezone
        
        # Convertir les dates en datetime aware si n√©cessaire
        if hasattr(self.date_debut, 'date'):
            date_debut = self.date_debut
        else:
            date_debut = self.date_debut
        
        if hasattr(self.date_fin, 'date'):
            date_fin = self.date_fin
        else:
            date_fin = self.date_fin
        
        # Si les dates sont des date (naive), les convertir en datetime aware
        from datetime import date, datetime
        if isinstance(date_debut, date) and not isinstance(date_debut, datetime):
            date_debut = timezone.make_aware(datetime.combine(date_debut, datetime.min.time()))
        if isinstance(date_fin, date) and not isinstance(date_fin, datetime):
            date_fin = timezone.make_aware(datetime.combine(date_fin, datetime.max.time()))
        
        logger.info(f"üîµ [DataCollector] Filtrage par dates: {date_debut} √† {date_fin}")
        
        # V√©rifier combien de fiches existent au total (sans filtre de date)
        total_fiches_db = CriminalFicheCriminelle.objects.count()
        logger.info(f"üîµ [DataCollector] Total fiches dans la base: {total_fiches_db}")
        
        # V√©rifier les dates min/max des fiches existantes
        try:
            fiche_min = CriminalFicheCriminelle.objects.order_by('date_creation').first()
            fiche_max = CriminalFicheCriminelle.objects.order_by('-date_creation').first()
            if fiche_min and fiche_max:
                logger.info(f"üîµ [DataCollector] Date min fiche: {fiche_min.date_creation}, Date max fiche: {fiche_max.date_creation}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [DataCollector] Erreur r√©cup√©ration dates min/max: {e}")
        
        # Filtrer par dates et exclure les fiches archiv√©es
        filter_kwargs = {
            'date_creation__gte': date_debut,
            'date_creation__lte': date_fin,
        }
        
        # Ajouter is_archived seulement si le champ existe
        try:
            CriminalFicheCriminelle._meta.get_field('is_archived')
            filter_kwargs['is_archived'] = False
            logger.info(f"üîµ [DataCollector] Filtre is_archived=False ajout√©")
        except:
            logger.info(f"üîµ [DataCollector] Champ is_archived n'existe pas, ignor√©")
        
        qs = CriminalFicheCriminelle.objects.filter(**filter_kwargs)
        
        count_filtered = qs.count()
        logger.info(f"üîµ [DataCollector] Nombre de fiches apr√®s filtrage par dates: {count_filtered}")
        
        # V√©rifier si une province est sp√©cifi√©e
        province_filter = self.filtres.get('province') or self.filtres.get('region')
        
        # Si aucune fiche n'est trouv√©e dans la p√©riode, essayer sans filtre de date
        if count_filtered == 0:
            logger.warning(f"‚ö†Ô∏è [DataCollector] Aucune fiche trouv√©e dans la p√©riode {date_debut} √† {date_fin}")
            
            # R√©initialiser le queryset sans filtre de date (mais garder les autres filtres)
            filter_kwargs_no_date = {}
            if 'is_archived' in filter_kwargs:
                filter_kwargs_no_date['is_archived'] = filter_kwargs['is_archived']
            
            qs_no_date = CriminalFicheCriminelle.objects.filter(**filter_kwargs_no_date)
            
            # Si une province est sp√©cifi√©e, l'appliquer maintenant
            if province_filter:
                logger.warning(f"‚ö†Ô∏è [DataCollector] Tentative sans filtre de date mais avec province '{province_filter}'")
                # Normaliser le nom de la province pour la recherche
                province_normalized = province_filter.strip().lower()
                qs_no_date = qs_no_date.filter(
                    Q(province__icontains=province_filter) |
                    Q(province__icontains=province_normalized) |
                    Q(lieu_arrestation__icontains=province_filter) |
                    Q(lieu_arrestation__icontains=province_normalized) |
                    Q(adresse__icontains=province_filter) |
                    Q(adresse__icontains=province_normalized)
                )
            else:
                logger.warning(f"‚ö†Ô∏è [DataCollector] Utilisation de TOUTES les fiches disponibles (sans filtre de date)")
            
            count_no_date = qs_no_date.count()
            if count_no_date > 0:
                logger.info(f"‚úÖ [DataCollector] {count_no_date} fiches trouv√©es sans filtre de date - utilisation de ces fiches")
                qs = qs_no_date
                count_filtered = count_no_date
            else:
                logger.warning(f"‚ö†Ô∏è [DataCollector] Aucune fiche trouv√©e m√™me sans filtre de date")
        
        # Ajouter les relations si elles existent
        try:
            qs = qs.select_related('statut_fiche')
        except:
            pass
        try:
            qs = qs.prefetch_related('infractions__type_infraction', 'infractions__statut_affaire')
        except:
            pass
        
        # Appliquer les autres filtres (statut, niveau_danger) si pas d√©j√† appliqu√©s
        if self.filtres.get('statut'):
            # Chercher le statut par code
            from criminel.models import RefStatutFiche
            try:
                statut = RefStatutFiche.objects.get(code=self.filtres['statut'])
                qs = qs.filter(statut_fiche=statut)
                logger.info(f"üîµ [DataCollector] Filtre statut appliqu√©: {self.filtres['statut']}")
            except:
                pass
        
        # Filtrer par province si pas d√©j√† fait (cas o√π des fiches √©taient trouv√©es avec les dates)
        if province_filter and count_filtered > 0:
            logger.info(f"üîµ [DataCollector] Filtre province appliqu√©: {province_filter}")
            
            # Normaliser le nom de la province pour la recherche (enlever les accents, espaces, etc.)
            province_normalized = province_filter.strip().lower()
            
            qs = qs.filter(
                Q(province__icontains=province_filter) |
                Q(province__icontains=province_normalized) |
                Q(lieu_arrestation__icontains=province_filter) |
                Q(lieu_arrestation__icontains=province_normalized) |
                Q(adresse__icontains=province_filter) |
                Q(adresse__icontains=province_normalized)
            )
            count_after_province = qs.count()
            logger.info(f"üîµ [DataCollector] Nombre de fiches apr√®s filtre province: {count_after_province}")
            
            # Si aucune fiche n'est trouv√©e avec le filtre de province, v√©rifier les provinces disponibles
            if count_after_province == 0:
                logger.warning(f"‚ö†Ô∏è [DataCollector] Aucune fiche trouv√©e pour la province '{province_filter}' dans la p√©riode sp√©cifi√©e")
                # Lister les provinces disponibles pour aider au diagnostic
                try:
                    provinces_disponibles = list(CriminalFicheCriminelle.objects.exclude(
                        province__isnull=True
                    ).exclude(
                        province=''
                    ).values_list('province', flat=True).distinct()[:10])
                    logger.info(f"üîµ [DataCollector] Provinces disponibles dans la base: {provinces_disponibles}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è [DataCollector] Erreur r√©cup√©ration provinces: {e}")
        
        if self.filtres.get('niveau_danger'):
            qs = qs.filter(niveau_danger=self.filtres['niveau_danger'])
            logger.info(f"üîµ [DataCollector] Filtre niveau_danger appliqu√©: {self.filtres['niveau_danger']}")
        
        if self.filtres.get('niveau_danger'):
            qs = qs.filter(niveau_danger=self.filtres['niveau_danger'])
        
        return qs
    
    # COLLECTEURS SP√âCIFIQUES
    
    def _collect_resume_mensuel(self) -> Dict[str, Any]:
        """Collecte les donn√©es pour le r√©sum√© mensuel"""
        import logging
        logger = logging.getLogger(__name__)
        
        try:
            qs = self._get_base_queryset()
            
            # Statistiques globales
            total_fiches = qs.count()
            logger.info(f"üîµ [DataCollector] Total fiches dans le queryset: {total_fiches}")
            
            # Si aucune fiche n'est trouv√©e, v√©rifier si c'est un probl√®me de dates
            if total_fiches == 0:
                total_all_fiches = CriminalFicheCriminelle.objects.count()
                logger.warning(f"‚ö†Ô∏è [DataCollector] AUCUNE fiche trouv√©e dans la p√©riode {self.date_debut} √† {self.date_fin}")
                logger.warning(f"‚ö†Ô∏è [DataCollector] Total fiches dans la base (toutes p√©riodes): {total_all_fiches}")
                
                # V√©rifier les dates min/max r√©elles
                try:
                    fiche_min = CriminalFicheCriminelle.objects.order_by('date_creation').first()
                    fiche_max = CriminalFicheCriminelle.objects.order_by('-date_creation').first()
                    if fiche_min and fiche_max:
                        logger.warning(f"‚ö†Ô∏è [DataCollector] P√©riode r√©elle des donn√©es: {fiche_min.date_creation} √† {fiche_max.date_creation}")
                        logger.warning(f"‚ö†Ô∏è [DataCollector] P√©riode demand√©e: {self.date_debut} √† {self.date_fin}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è [DataCollector] Erreur r√©cup√©ration dates: {e}")
            
            # Compter par statut - avec gestion d'erreur
            fiches_ouvertes = 0
            fiches_closes = 0
            try:
                from criminel.models import RefStatutFiche
                statuts_en_cours = RefStatutFiche.objects.filter(code__in=['en_cours', 'en_attente'])
                logger.info(f"üîµ [DataCollector] Statuts en cours trouv√©s: {list(statuts_en_cours.values_list('code', flat=True))}")
                fiches_ouvertes = qs.filter(statut_fiche__in=statuts_en_cours).count()
                logger.info(f"üîµ [DataCollector] Fiches ouvertes: {fiches_ouvertes}")
                
                statuts_closes = RefStatutFiche.objects.filter(code__in=['cloture', 'clos'])
                logger.info(f"üîµ [DataCollector] Statuts clos trouv√©s: {list(statuts_closes.values_list('code', flat=True))}")
                fiches_closes = qs.filter(statut_fiche__in=statuts_closes).count()
                logger.info(f"üîµ [DataCollector] Fiches closes: {fiches_closes}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [DataCollector] Erreur calcul statuts: {e}", exc_info=True)
                fiches_ouvertes = total_fiches
                fiches_closes = 0
            
            # √âvolution par jour - avec gestion d'erreur
            evolution_quotidienne = []
            try:
                evolution_quotidienne = list(qs.annotate(
                    jour=TruncDay('date_creation')
                ).values('jour').annotate(
                    nombre=Count('id')
                ).order_by('jour'))
            except Exception as e:
                import logging
                logger = logging.getLogger(__name__)
                logger.warning(f"Erreur √©volution quotidienne: {e}")
                evolution_quotidienne = []
            
            # Moyenne niveau de danger - avec gestion d'erreur
            avg_danger = 0.0
            try:
                avg_danger = qs.aggregate(avg=Avg('niveau_danger'))['avg'] or 0.0
            except Exception as e:
                import logging
                logger = logging.getLogger(__name__)
                logger.warning(f"Erreur moyenne danger: {e}")
            
            return {
                'titre': 'R√©sum√© Mensuel',
                'resume': f"Ce rapport pr√©sente un r√©sum√© complet de l'activit√© du {self.date_debut} au {self.date_fin}.",
                'statistiques': {
                    'Total des fiches': total_fiches,
                    'Fiches ouvertes': fiches_ouvertes,
                    'Fiches cl√¥tur√©es': fiches_closes,
                    'Taux de cl√¥ture': f"{(fiches_closes / total_fiches * 100) if total_fiches > 0 else 0:.1f}%",
                    'Niveau de danger moyen': f"{avg_danger:.2f}",
                },
                'donnees': evolution_quotidienne,
                'graphiques': {
                    'evolution_quotidienne': evolution_quotidienne
                }
            }
        except Exception as e:
            import logging
            logger = logging.getLogger(__name__)
            logger.error(f"Erreur _collect_resume_mensuel: {e}", exc_info=True)
            return {
                'titre': 'R√©sum√© Mensuel',
                'resume': f"Erreur lors de la collecte: {str(e)}",
                'statistiques': {
                    'Total des fiches': 0,
                    'Fiches ouvertes': 0,
                    'Fiches cl√¥tur√©es': 0,
                    'Taux de cl√¥ture': '0.0%',
                    'Niveau de danger moyen': '0.00',
                },
                'donnees': [],
                'graphiques': {},
                'erreur': True
            }
    
    def _collect_statistiques_infractions(self) -> Dict[str, Any]:
        """Collecte les statistiques sur les infractions"""
        qs = self._get_base_queryset()
        
        # Compter les infractions par type
        from criminel.models import CriminalInfraction
        infractions = CriminalInfraction.objects.filter(
            fiche__in=qs
        ).select_related('type_infraction', 'statut_affaire')
        
        # R√©partition par type d'infraction
        repartition_type = list(infractions.values('type_infraction__libelle').annotate(
            nombre=Count('id')
        ).order_by('-nombre')[:10])
        
        # R√©partition par statut de fiche
        repartition_statut = list(qs.values('statut_fiche__libelle').annotate(
            nombre=Count('id')
        ).order_by('-nombre'))
        
        # R√©partition par niveau de danger
        repartition_danger = list(qs.values('niveau_danger').annotate(
            nombre=Count('id')
        ).order_by('-niveau_danger'))
        
        # Donn√©es d√©taill√©es pour export
        donnees_detaillees = []
        for fiche in qs[:100]:  # Limiter √† 100 pour performance
            infractions_fiche = fiche.infractions.all()
            for infraction in infractions_fiche:
                donnees_detaillees.append({
                    'numero_fiche': fiche.numero_fiche,
                    'nom': fiche.nom,
                    'prenom': fiche.prenom or '',
                    'date_creation': fiche.date_creation.strftime('%Y-%m-%d') if fiche.date_creation else '',
                    'statut': fiche.statut_fiche.libelle if fiche.statut_fiche else 'Non d√©fini',
                    'type_infraction': infraction.type_infraction.libelle if infraction.type_infraction else 'Non d√©fini',
                    'date_infraction': infraction.date_infraction.strftime('%Y-%m-%d') if infraction.date_infraction else '',
                    'lieu': infraction.lieu or '',
                    'niveau_danger': fiche.niveau_danger,
                })
        
        total_infractions = infractions.count()
        
        return {
            'titre': 'Statistiques des Infractions',
            'resume': f"Analyse d√©taill√©e des infractions enregistr√©es entre le {self.date_debut} et le {self.date_fin}.",
            'statistiques': {
                'Total fiches': qs.count(),
                'Total infractions': total_infractions,
                'Moyenne infractions/fiche': f"{(total_infractions / qs.count()) if qs.count() > 0 else 0:.2f}",
                'Niveau danger moyen': f"{qs.aggregate(avg=Avg('niveau_danger'))['avg'] or 0:.2f}",
            },
            'donnees': repartition_type,
            'repartition_statut': repartition_statut,
            'repartition_danger': repartition_danger,
            'details': donnees_detaillees[:50],  # Limiter pour export
        }
    
    def _collect_activite_agents(self) -> Dict[str, Any]:
        """Collecte les donn√©es sur l'activit√© des agents - VRAIES DONN√âES"""
        from utilisateur.models import UtilisateurModel
        
        # Agents actifs avec leurs vraies donn√©es
        agents = UtilisateurModel.objects.filter(
            statut='actif'
        ).exclude(
            role__isnull=True
        ).exclude(
            role=''  # Exclure les agents sans r√¥le d√©fini
        )
        
        # Filtrer les agents enqu√™teurs/analystes selon les r√¥les disponibles
        roles_enqueteurs = ['Enqu√™teur Principal', 'Analyste', 'Enqu√™teur', 'Enqu√™teur Junior']
        agents = agents.filter(role__in=roles_enqueteurs)
        
        total_agents = agents.count()
        
        date_limite = timezone.now() - timedelta(days=7)
        agents_actifs = 0
        agents_donnees = []
        
        for agent in agents:
            is_actif_recent = False
            derniere_connexion_str = 'Jamais'
            
            if agent.derniereConnexion:
                derniere_connexion_str = agent.derniereConnexion.strftime('%Y-%m-%d %H:%M')
                if agent.derniereConnexion >= date_limite:
                    is_actif_recent = True
                    agents_actifs += 1
            elif agent.last_login:
                derniere_connexion_str = agent.last_login.strftime('%Y-%m-%d %H:%M')
                if agent.last_login >= date_limite:
                    is_actif_recent = True
                    agents_actifs += 1
            
            agents_donnees.append({
                'email': agent.email,
                'prenom': agent.prenom or '',
                'nom': agent.nom or '',
                'username': agent.username or '',
                'role': agent.role or 'Non d√©fini',
                'statut': agent.statut or 'actif',
                'grade': agent.grade or '',
                'matricule': agent.matricule or '',
                'derniere_connexion': derniere_connexion_str,
                'est_actif_recent': is_actif_recent,
                'date_creation_compte': agent.dateCreation.strftime('%Y-%m-%d') if agent.dateCreation else '',
            })
        
        total_fiches_periode = CriminalFicheCriminelle.objects.filter(
            date_creation__gte=self.date_debut,
            date_creation__lte=self.date_fin,
            is_archived=False
        ).count()
        
        return {
            'titre': 'Activit√© des Agents',
            'resume': f"Rapport d'activit√© des agents entre le {self.date_debut} et le {self.date_fin}. Total de {total_fiches_periode} fiches cr√©√©es dans cette p√©riode.",
            'statistiques': {
                'Total agents': total_agents,
                'Agents actifs (7j)': agents_actifs,
                'Taux d\'activit√©': f"{(agents_actifs / total_agents * 100) if total_agents > 0 else 0:.1f}%",
                'Total fiches cr√©√©es (p√©riode)': total_fiches_periode,
                'Moyenne fiches/agent': f"{(total_fiches_periode / total_agents) if total_agents > 0 else 0:.1f}",
            },
            'donnees': agents_donnees
        }
    
    def _collect_fiches_ouvertes(self) -> Dict[str, Any]:
        """Collecte les fiches criminelles ouvertes"""
        from criminel.models import RefStatutFiche
        
        statuts_ouverts = RefStatutFiche.objects.filter(code__in=['en_cours', 'en_attente'])
        qs = self._get_base_queryset().filter(statut_fiche__in=statuts_ouverts)
        
        # Donn√©es d√©taill√©es
        donnees = []
        for fiche in qs[:500]:  # Limiter pour performance
            donnees.append({
                'numero_fiche': fiche.numero_fiche,
                'nom': fiche.nom,
                'prenom': fiche.prenom or '',
                'surnom': fiche.surnom or '',
                'date_creation': fiche.date_creation.strftime('%Y-%m-%d %H:%M') if fiche.date_creation else '',
                'province': fiche.province or '',
                'lieu_arrestation': fiche.lieu_arrestation or '',
                'statut': fiche.statut_fiche.libelle if fiche.statut_fiche else 'Non d√©fini',
                'niveau_danger': fiche.niveau_danger,
                'nombre_infractions': fiche.infractions.count(),
            })
        
        # Calculer les dur√©es
        maintenant = datetime.now()
        anciennes = 0
        recentes = 0
        for fiche in qs:
            if fiche.date_creation:
                jours = (maintenant - fiche.date_creation.replace(tzinfo=None)).days
                if jours > 30:
                    anciennes += 1
                elif jours <= 7:
                    recentes += 1
        
        return {
            'titre': 'Fiches Ouvertes',
            'resume': f"Liste des fiches criminelles en cours d'investigation au {self.date_fin}.",
            'statistiques': {
                'Total fiches ouvertes': qs.count(),
                'Anciennes (>30j)': anciennes,
                'R√©centes (<7j)': recentes,
                'Niveau danger moyen': f"{qs.aggregate(avg=Avg('niveau_danger'))['avg'] or 0:.2f}",
            },
            'donnees': donnees[:100],  # Limiter pour export
        }
    
    def _collect_analyse_geographique(self) -> Dict[str, Any]:
        """Analyse g√©ographique des infractions"""
        qs = self._get_base_queryset()
        
        # R√©partition par province
        repartition_province = list(qs.exclude(province__isnull=True).exclude(province='').values('province').annotate(
            nombre=Count('id')
        ).order_by('-nombre')[:10])  # Top 10 provinces
        
        # R√©partition par lieu d'arrestation
        repartition_lieu = list(qs.exclude(lieu_arrestation__isnull=True).exclude(lieu_arrestation='').values('lieu_arrestation').annotate(
            nombre=Count('id')
        ).order_by('-nombre')[:20])  # Top 20 lieux
        
        # Fiches avec coordonn√©es GPS
        fiches_gps = qs.exclude(latitude__isnull=True).exclude(longitude__isnull=True).count()
        
        return {
            'titre': 'Analyse G√©ographique',
            'resume': f"R√©partition territoriale des fiches criminelles du {self.date_debut} au {self.date_fin}.",
            'statistiques': {
                'Total fiches': qs.count(),
                'Fiches avec GPS': fiches_gps,
                'Pourcentage avec GPS': f"{(fiches_gps / qs.count() * 100) if qs.count() > 0 else 0:.1f}%",
                'Nombre de provinces': len(repartition_province),
                'Province la plus touch√©e': repartition_province[0]['province'] if repartition_province else 'N/A',
            },
            'donnees': repartition_province,
            'lieux_detail': repartition_lieu,
        }
    
    def _collect_taux_resolution(self) -> Dict[str, Any]:
        """Calcule les taux de r√©solution"""
        qs = self._get_base_queryset()
        
        total = qs.count()
        
        # Utiliser les vrais statuts de la base
        from criminel.models import RefStatutFiche
        statuts_closes = RefStatutFiche.objects.filter(code__in=['cloture', 'clos', 'clotur√©'])
        resolues = qs.filter(statut_fiche__in=statuts_closes).count()
        
        statuts_en_cours = RefStatutFiche.objects.filter(code__in=['en_cours', 'en_attente'])
        en_cours = qs.filter(statut_fiche__in=statuts_en_cours).count()
        
        fiches_closes = qs.filter(statut_fiche__in=statuts_closes)
        temps_resolution_jours = []
        for fiche in fiches_closes:
            if fiche.date_creation and fiche.date_modification:
                delta = (fiche.date_modification - fiche.date_creation).days
                if delta > 0:
                    temps_resolution_jours.append(delta)
        
        temps_moyen = sum(temps_resolution_jours) / len(temps_resolution_jours) if temps_resolution_jours else 0
        
        taux_resolution = (resolues / total * 100) if total > 0 else 0
        
        return {
            'titre': 'Taux de R√©solution',
            'resume': f"Performance de r√©solution des cas du {self.date_debut} au {self.date_fin}.",
            'statistiques': {
                'Total cas': total,
                'Cas r√©solus': resolues,
                'Cas en cours': en_cours,
                'Taux de r√©solution': f"{taux_resolution:.1f}%",
                'Temps moyen de r√©solution': f"{temps_moyen:.1f} jours",
            },
            'donnees': [
                {'statut': 'R√©solus', 'nombre': resolues},
                {'statut': 'En cours', 'nombre': en_cours},
                {'statut': 'Autres', 'nombre': total - resolues - en_cours},
            ],
        }
    
    def _collect_biometrie(self) -> Dict[str, Any]:
        """Collecte les donn√©es biom√©triques depuis la base"""
        qs = self._get_base_queryset()
        
        # Compter les fiches avec photos
        fiches_avec_photos = qs.exclude(photo__isnull=True).exclude(photo='').count()
        
        # Chercher les empreintes digitales si le mod√®le existe
        try:
            from biometrie.models import EmpreinteDigitale
            empreintes_total = EmpreinteDigitale.objects.filter(
                fiche_criminelle__in=qs
            ).count()
        except:
            empreintes_total = 0
        
        # Chercher les photos biom√©triques si le mod√®le existe
        try:
            from biometrie.models import PhotoBiometrique
            photos_biometriques = PhotoBiometrique.objects.filter(
                fiche_criminelle__in=qs
            ).count()
        except:
            photos_biometriques = 0
        
        # Statistiques d√©taill√©es
        donnees = []
        for fiche in qs[:100]:  # Limiter pour performance
            donnees_fiche = {
                'numero_fiche': fiche.numero_fiche,
                'nom': fiche.nom,
                'prenom': fiche.prenom or '',
                'a_photo': bool(fiche.photo),
            }
            
            # Ajouter les empreintes si disponibles
            try:
                from biometrie.models import EmpreinteDigitale
                empreintes = EmpreinteDigitale.objects.filter(fiche_criminelle=fiche).count()
                donnees_fiche['nombre_empreintes'] = empreintes
            except:
                donnees_fiche['nombre_empreintes'] = 0
            
            donnees.append(donnees_fiche)
        
        return {
            'titre': 'Donn√©es Biom√©triques',
            'resume': f"Rapport biom√©trique pour la p√©riode du {self.date_debut} au {self.date_fin}.",
            'statistiques': {
                'Total fiches analys√©es': qs.count(),
                'Fiches avec photo': fiches_avec_photos,
                'Pourcentage avec photo': f"{(fiches_avec_photos / qs.count() * 100) if qs.count() > 0 else 0:.1f}%",
                'Empreintes digitales enregistr√©es': empreintes_total,
                'Photos biom√©triques': photos_biometriques,
            },
            'donnees': donnees[:50],  # Limiter pour export
        }
    
    def _collect_personnalise(self) -> Dict[str, Any]:
        """Collecte pour un rapport personnalis√©"""
        qs = self._get_base_queryset()
        
        # Donn√©es d√©taill√©es
        donnees = []
        for fiche in qs[:500]:  # Limiter pour performance
            donnees.append({
                'numero_fiche': fiche.numero_fiche,
                'nom': fiche.nom,
                'prenom': fiche.prenom or '',
                'surnom': fiche.surnom or '',
                'sexe': fiche.get_sexe_display() if hasattr(fiche, 'get_sexe_display') else fiche.sexe,
                'date_naissance': fiche.date_naissance.strftime('%Y-%m-%d') if fiche.date_naissance else '',
                'nationalite': fiche.nationalite or '',
                'province': fiche.province or '',
                'lieu_arrestation': fiche.lieu_arrestation or '',
                'date_arrestation': fiche.date_arrestation.strftime('%Y-%m-%d') if fiche.date_arrestation else '',
                'date_creation': fiche.date_creation.strftime('%Y-%m-%d %H:%M') if fiche.date_creation else '',
                'statut': fiche.statut_fiche.libelle if fiche.statut_fiche else 'Non d√©fini',
                'niveau_danger': fiche.niveau_danger,
                'nombre_infractions': fiche.infractions.count(),
            })
        
        return {
            'titre': 'Rapport Personnalis√©',
            'resume': f"Rapport personnalis√© couvrant la p√©riode du {self.date_debut} au {self.date_fin}.",
            'statistiques': {
                'Total fiches': qs.count(),
                'Fiches avec infractions': qs.filter(infractions__isnull=False).distinct().count(),
                'Niveau danger moyen': f"{qs.aggregate(avg=Avg('niveau_danger'))['avg'] or 0:.2f}",
            },
            'donnees': donnees,
        }

